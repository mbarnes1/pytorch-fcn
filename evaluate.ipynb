{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 17 12:05:47 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    85W / 149W |  11171MiB / 11439MiB |     59%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla K80           Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    74W / 149W |   8312MiB / 11439MiB |     35%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla K80           Off  | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    94W / 149W |   8312MiB / 11439MiB |     50%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla K80           Off  | 00000000:09:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    92W / 149W |  10923MiB / 11439MiB |     32%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla K80           Off  | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   61C    P0   100W / 149W |  10927MiB / 11439MiB |     46%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla K80           Off  | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   54C    P0   145W / 149W |   8263MiB / 11439MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla K80           Off  | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   62C    P0    98W / 149W |  10927MiB / 11439MiB |     68%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla K80           Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   144W / 149W |   8263MiB / 11439MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     11445      C   ...arnes1/miniconda2/envs/torch/bin/python   942MiB |\n",
      "|    0     25170      C   python                                      6162MiB |\n",
      "|    0     30234      C   python                                      4045MiB |\n",
      "|    1     25976      C   python                                      8299MiB |\n",
      "|    2     25311      C   python                                      8299MiB |\n",
      "|    3     25928      C   python                                     10906MiB |\n",
      "|    4     25390      C   python                                     10906MiB |\n",
      "|    5     17997      C   python                                      8252MiB |\n",
      "|    6     10081      C   python                                     10906MiB |\n",
      "|    7     12978      C   python                                      8252MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import fcn\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchfcn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[/zfsauton/home/mbarnes1/data/models/pytorch/fcn32s_from_caffe.pth] Checking md5 (8acf386d722dc3484625964cbe2aba49)\n"
     ]
    }
   ],
   "source": [
    "model_file = torchfcn.models.fcn32s.FCN32s.download()\n",
    "root = osp.expanduser('~/data/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/zfsauton/home/mbarnes1/data/models/pytorch/fcn32s_from_caffe.pth'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        torchfcn.datasets.VOC2011ClassSeg(\n",
    "            root, split='seg11valid', transform=True),\n",
    "        batch_size=1, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "n_class = len(val_loader.dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading FCN32s model file: /zfsauton/home/mbarnes1/data/models/pytorch/fcn32s_from_caffe.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCN32s(\n",
       "  (conv1_1): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(100, 100))\n",
       "  (relu1_1): ReLU(inplace)\n",
       "  (conv1_2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu1_2): ReLU(inplace)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv2_1): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_1): ReLU(inplace)\n",
       "  (conv2_2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu2_2): ReLU(inplace)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv3_1): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_1): ReLU(inplace)\n",
       "  (conv3_2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_2): ReLU(inplace)\n",
       "  (conv3_3): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu3_3): ReLU(inplace)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv4_1): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_1): ReLU(inplace)\n",
       "  (conv4_2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_2): ReLU(inplace)\n",
       "  (conv4_3): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu4_3): ReLU(inplace)\n",
       "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (conv5_1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_1): ReLU(inplace)\n",
       "  (conv5_2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_2): ReLU(inplace)\n",
       "  (conv5_3): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu5_3): ReLU(inplace)\n",
       "  (pool5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (fc6): Conv2d (512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (relu6): ReLU(inplace)\n",
       "  (drop6): Dropout2d(p=0.5)\n",
       "  (fc7): Conv2d (4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu7): ReLU(inplace)\n",
       "  (drop7): Dropout2d(p=0.5)\n",
       "  (score_fr): Conv2d (4096, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (upscore): ConvTranspose2d (21, 21, kernel_size=(64, 64), stride=(32, 32), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if osp.basename(model_file).startswith('fcn32s'):\n",
    "    model = torchfcn.models.FCN32s(n_class=21)\n",
    "elif osp.basename(model_file).startswith('fcn16s'):\n",
    "    model = torchfcn.models.FCN16s(n_class=21)\n",
    "elif osp.basename(model_file).startswith('fcn8s'):\n",
    "    if osp.basename(model_file).startswith('fcn8s-atonce'):\n",
    "        model = torchfcn.models.FCN8sAtOnce(n_class=21)\n",
    "    else:\n",
    "        model = torchfcn.models.FCN8s(n_class=21)\n",
    "else:\n",
    "    raise ValueError\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "print('==> Loading %s model file: %s' %\n",
    "      (model.__class__.__name__, model_file))\n",
    "model_data = torch.load(model_file)\n",
    "try:\n",
    "    model.load_state_dict(model_data)\n",
    "except Exception:\n",
    "    model.load_state_dict(model_data['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchfcn.trainer import cross_entropy2d, MSEAdjacencyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "mse_loss = MSEAdjacencyLoss(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "## Make predictions\n",
    "visualizations = []\n",
    "label_trues, label_preds = [], []\n",
    "loss_cross_entropy = 0\n",
    "loss_mse = 0\n",
    "loss_mse_naive_zero = 0  # the loss \n",
    "loss_mse_naive_one = 0\n",
    "n_samples = 0\n",
    "for batch_idx, (data, target) in tqdm.tqdm(enumerate(val_loader),\n",
    "                                           total=len(val_loader),\n",
    "                                           ncols=80, leave=False):\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    score = model(data)\n",
    "    n_samples += score.size(0)\n",
    "    loss_cross_entropy += cross_entropy2d(score, target, size_average=False)\n",
    "    loss_mse += mse_loss(F.softmax(score, dim=1), target)\n",
    "    loss_mse_naive_zero += mse_loss(Variable(score.data.new(score.size()).fill_(0.0)), target)\n",
    "    all_one_cluster = Variable(score.data.new(score.size()).fill_(0.0))\n",
    "    all_one_cluster[:, 1, :, :] = 1.0\n",
    "    loss_mse_naive_one += mse_loss(all_one_cluster, target)\n",
    "    \n",
    "    \n",
    "    imgs = data.data.cpu()\n",
    "    lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "    lbl_true = target.data.cpu()\n",
    "    for img, lt, lp in zip(imgs, lbl_true, lbl_pred):\n",
    "        img, lt = val_loader.dataset.untransform(img, lt)\n",
    "        label_trues.append(lt)\n",
    "        label_preds.append(lp)\n",
    "        # TODO: Visualizations (get cv2 installed on server)\n",
    "        #if len(visualizations) < 9:\n",
    "        #    viz = fcn.utils.visualize_segmentation(\n",
    "        #        lbl_pred=lp, lbl_true=lt, img=img, n_class=n_class,\n",
    "        #        label_names=val_loader.dataset.class_names)\n",
    "        #    visualizations.append(viz)\n",
    "    if batch_idx > 10:\n",
    "        break\n",
    "loss_cross_entropy /= n_samples\n",
    "loss_mse /= n_samples\n",
    "loss_mse_naive_zero /= n_samples\n",
    "loss_mse_naive_one /= n_samples\n",
    "loss_cross_entropy = loss_cross_entropy.data[0]\n",
    "loss_mse = loss_mse.data[0]\n",
    "loss_mse_naive_zero = loss_mse_naive_zero.data[0]\n",
    "loss_mse_naive_one = loss_mse_naive_one.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save predictions and labels for later\n",
    "import cPickle as pickle\n",
    "pickle.dump(label_trues, open( \"labels_trues.p\", \"wb\" ) )\n",
    "pickle.dump(label_preds, open( \"labels_preds.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labels_to_adjacency(labels):\n",
    "    \"\"\"\n",
    "    :param labels: N x M LongTensor Variable, where N is the batch size and M is the number of nodes.\n",
    "    :return adjacency: N x M x M FloatTensor Variable.\n",
    "    \"\"\"\n",
    "    m = labels.size(1)\n",
    "    labels = labels.unsqueeze(dim=1).expand(-1, m, -1)  # N x M x M matrix\n",
    "    adjacency = (labels == labels.transpose(1, 2)).float()\n",
    "    return adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7291fbbda0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minput_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# N x C x n_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtarget_subsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_indices\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# N x n_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minput_adjacency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_subsample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_subsample\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# N x n_nodes x n_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtarget_adjacency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_to_adjacency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_subsample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#off_diagonal_mask = ~torch.eye(self._n_nodes).byte().unsqueeze(dim=0).expand(n, -1, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "import random\n",
    "input = Variable(score.data.new(score.size()).fill_(0.0))\n",
    "n_nodes = 10000\n",
    "n, c, h, w = input.size()\n",
    "total_nodes_per_image = c * h\n",
    "assert total_nodes_per_image >= n_nodes\n",
    "random_indices = Variable(target.data.new(random.sample(xrange(total_nodes_per_image), n_nodes * n)).view(n, n_nodes))  # n x n_nodes\n",
    "\n",
    "# Compute loss\n",
    "input_subsample = torch.gather(input.view(n, c, -1), 2, random_indices.unsqueeze(dim=1).expand(-1, c, -1))  # N x C x n_nodes\n",
    "target_subsample = torch.gather(target.view(n, -1), 1, random_indices)  # N x n_nodes\n",
    "input_adjacency = torch.bmm(input_subsample.transpose(1, 2), input_subsample)  # N x n_nodes x n_nodes\n",
    "target_adjacency = labels_to_adjacency(target_subsample.view(n, -1))\n",
    "#off_diagonal_mask = ~torch.eye(self._n_nodes).byte().unsqueeze(dim=0).expand(n, -1, -1)\n",
    "#loss = self._mse(input_adjacency[off_diagonal_mask], target_adjacency[off_diagonal_mask])  # MSE per edge, excluding self edges\n",
    "#loss = torch.norm(input_adjacency - target_adjacency, p=2) / (self._n_nodes ** 2)  # Frobenius norm per edge\n",
    "mse = torch.nn.MSELoss()\n",
    "loss = mse(input_adjacency, target_adjacency)  # MSE per edge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics\n",
    "print('''\\\n",
    "Validation cross-entropy loss per sample: {}\n",
    "Validation MSE (our predictions) loss per sample: {}\n",
    "Validation MSE (naively predict all in different clusters, no self edges) loss per sample: {}\n",
    "Validation MSE (naively predict all in same cluster) loss per sample: {}\n",
    "'''.format(loss_cross_entropy, loss_mse, loss_mse_naive_zero, loss_mse_naive_one))\n",
    "metrics = torchfcn.utils.label_accuracy_score(label_trues, label_preds, n_class=n_class)\n",
    "metrics = np.array(metrics)\n",
    "metrics *= 100\n",
    "print('''\\\n",
    "Accuracy: {0}\n",
    "Accuracy Class: {1}\n",
    "Mean IU: {2}\n",
    "FWAV Accuracy: {3}'''.format(*metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization\n",
    "viz = fcn.utils.get_tile_image(visualizations)\n",
    "skimage.io.imsave('viz_evaluate.png', viz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
